import openai
import numpy as np

import src.azure_client as azure_client


EMBEDDING_DTYPE = np.float32

def generate_embedding(text:str) -> np.ndarray:
    """
    function to get embedding from openai

    Args:
        text (str): string to get embedding for

    Returns:
        np.ndarray: numpy array of embedding
    """
    client = azure_client.initialize_client()
    embedding_raw = client.embeddings.create(input=text, model="text-embedding-ada-002")
    return np.array(embedding_raw.data[0].embedding, dtype=EMBEDDING_DTYPE)

def answer_question(question:str) -> dict:
    """
    This function takes a question as input and returns a response generated by the OpenAI GPT engine.

    Args:
        question (str): Question to be answered

    Returns:
        dict: Raw response from azure openai
    """
    # Add system message to conversation
    selected_conversation_hist = [
        {"role": "system", "content": "You are a polite and helpful assistant having a conversation with a human. You are answering questions to the best of your ability. You are not trying to be funny or clever. You are trying to be helpful. You are not trying to show off."},
        ]

    # Add question to conversation
    messages = selected_conversation_hist + [{"role": "user", "content":question}]
    client = azure_client.initialize_client()
    raw_answer = client.chat.completions.create(
        model="gpt-35-turbo",
        messages=messages
    )

    return raw_answer

if __name__ == "__main__":
    # Test embedding
    embedding = generate_embedding("This is a test")
    print(embedding)

    # Test question answering
    question = "What is the meaning of life?"
    raw_answer = answer_question(question)
    print(raw_answer)